{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from data import *\n",
    "\n",
    "# Filler value for logically skipped ones\n",
    "filler_value = -999\n",
    "\n",
    "# Define the conditions dictionary for each column of the education module\n",
    "# Format: { column_name: { 'value': (skip_to_column_index, action_type) } }\n",
    "education_conditions = {\n",
    "    \"q03\": {2: \"skip_row\", \"NO\": \"skip_row\"},\n",
    "    \"Q08\": {2: \"Q11\", \"NO\": \"Q11\"},\n",
    "    \"Q09\": {1: \"Q12\", \"YES\": \"Q12\"},\n",
    "    \"Q10\": {range(1, 14): \"Q14\"},\n",
    "    \"Q11\": {range(1, 15): \"Q14\"},\n",
    "    \"Q14\": {2: \"Q17\", \"NO\": \"Q17\"},\n",
    "    \"Q15\": {1: \"Q21\", \"YES\": \"Q21\"},\n",
    "    \"Q16\": {range(1, 14): \"Q20\"},\n",
    "    \"Q19\": {2: \"skip_row\", \"NO\": \"skip_row\"},\n",
    "    \"Q20\": {range(1, 3): \"skip_row\", \"NO\": \"skip_row\"},\n",
    "    \"Q24\": {lambda x: x < 5: \"Q26\", \"ABROAD\": \"Q33\", 999: \"Q33\"},\n",
    "    \"Q28\": {range(1, 4): \"Q32\", \"WALK\": \"Q32\", \"BICYCLE\": \"Q32\", \"ANIMAL\": \"Q32\"},\n",
    "    \"Q30\": {2: \"Q32\", \"NO\": \"Q32\"},\n",
    "    \"Q43\": {1: \"Q45\", \"YES\": \"Q45\"},\n",
    "    \"Q46\": {2: \"Q50\", \"NO\": \"Q50\"},\n",
    "    \"Q48\": {4: \"Q50\", \"STILL HAVE NOT RECEIVED THE SUBSIDY\": \"Q50\"},\n",
    "    \"Q50\": {2: \"Q57\", \"NO\": \"Q57\"},\n",
    "    \"Q54\": {2: \"Q57\", \"NO\": \"Q57\"},\n",
    "    \"Q57\": {2: \"Q59\", \"NO\": \"Q59\"},\n",
    "    \"Q59\": {2: \"Q61\", \"NO\": \"Q61\"},\n",
    "    \"Q61\": {2: \"Q64\", \"NO\": \"Q64\"},\n",
    "    \"Q64\": {2: \"Q66\", \"NO\": \"Q66\"},\n",
    "}\n",
    "\n",
    "house_conditions = {\n",
    "    \"q05y\": {range(12): \"q09\"},\n",
    "    \"q06\": {range(4, 6): \"q09\", \"WIDOW/ER\": \"q09\", \"SINGLE\": \"q09\"},\n",
    "    \"q07\": {2: \"q09\", \"NO\": \"q09\"},\n",
    "    \"q11\": {2: \"q13\", \"NO\": \"q13\"},\n",
    "    \"q12\": {\"not_null\": \"q17\"},\n",
    "    \"q14\": {1: \"q16\", \"YES\": \"q16\"},\n",
    "    \"q15\": {\"not_null\": \"q17\"},\n",
    "    \"q17\": {2: \"q19\", \"NO\": \"q19\"},\n",
    "    \"q18\": {\"not_null\": \"skip_row\"},\n",
    "    \"q20\": {1: \"q22\", \"YES\": \"q22\"},\n",
    "    \"q21\": {\"not_null\": \"skip_row\"},\n",
    "}\n",
    "\n",
    "\n",
    "# Function to apply conditions based on the dictionary with column names on the education module.\n",
    "# Define new category (filler_value), for those which should be skipped.\n",
    "def apply_conditions(df, conditions):\n",
    "    def apply_action(df, idx, col_name, action):\n",
    "        \"\"\"Helper function to apply the specified action.\"\"\"\n",
    "        start_col_index = df.columns.get_loc(col_name)\n",
    "        if action == \"skip_row\":\n",
    "            # Set all columns to the right (from col_name to end of row) to filler_value\n",
    "            df.loc[idx, df.columns[start_col_index + 1 :]] = filler_value\n",
    "            return True  # Indicate that the row should be skipped\n",
    "        elif isinstance(action, str) and action in df.columns:\n",
    "            # Skip to a specific column within the row and set cells to 'skipped'\n",
    "            end_col_index = df.columns.get_loc(action)\n",
    "            df.loc[idx, df.columns[start_col_index + 1 : end_col_index]] = filler_value\n",
    "            return False\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        for col_name, condition in conditions.items():\n",
    "            if col_name in df.columns:\n",
    "                value = row[col_name]\n",
    "\n",
    "                # Check if thereâ€™s a condition for the value in this column\n",
    "                for cond_value, action in condition.items():\n",
    "                    if isinstance(cond_value, range):\n",
    "                        if value in cond_value:\n",
    "                            if apply_action(df, idx, col_name, action):\n",
    "                                break\n",
    "                        elif value == filler_value or pd.isna(value):\n",
    "                            continue\n",
    "                    elif callable(cond_value):\n",
    "                        if cond_value(value):\n",
    "                            if apply_action(df, idx, col_name, action):\n",
    "                                break\n",
    "                    elif (value == cond_value) or (\n",
    "                        cond_value == \"not_null\" and pd.notna(value)\n",
    "                    ):\n",
    "                        if apply_action(df, idx, col_name, action):\n",
    "                            break\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply the conditions to the DataFrame\n",
    "df_edu = apply_conditions(edu_train, education_conditions)\n",
    "df_house = apply_conditions(house_train, house_conditions)\n",
    "df_edu_test = apply_conditions(edu_test, education_conditions)\n",
    "df_house_test = apply_conditions(house_test, house_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "df_edu.to_csv(os.path.join(PROCESSED_DIR, \"education_train.csv\"), index=False)\n",
    "df_house.to_csv(os.path.join(PROCESSED_DIR, \"household_train.csv\"), index=False)\n",
    "df_edu_test.to_csv(os.path.join(PROCESSED_DIR, \"education_test.csv\"), index=False)\n",
    "df_house_test.to_csv(os.path.join(PROCESSED_DIR, \"household_test.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_house[\"psu_hh_idcode\"] = (\n",
    "    df_house[\"psu\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_house[\"hh\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_house[\"idcode\"].astype(str)\n",
    ")\n",
    "df_edu[\"psu_hh_idcode\"] = (\n",
    "    df_edu[\"psu\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_edu[\"hh\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_edu[\"idcode\"].astype(str)\n",
    ")\n",
    "\n",
    "df_house_prefixed = df_house.drop(columns=[\"psu\", \"hh\", \"idcode\", \"hhid\"]).add_prefix(\n",
    "    HOUSE_PREFIX\n",
    ")\n",
    "df_edu_prefixed = df_edu.drop(columns=[\"psu\", \"hh\", \"idcode\"]).add_prefix(EDU_PREFIX)\n",
    "\n",
    "# remove prefix on the key merge column \"psh_hh_idcode\"\n",
    "df_house_prefixed = df_house_prefixed.rename(\n",
    "    columns={\"house_psu_hh_idcode\": \"psu_hh_idcode\"}\n",
    ")\n",
    "df_edu_prefixed = df_edu_prefixed.rename(columns={\"edu_psu_hh_idcode\": \"psu_hh_idcode\"})\n",
    "\n",
    "combined_transformed_train = pd.merge(\n",
    "    pd.merge(\n",
    "        pov_train,\n",
    "        df_house_prefixed,\n",
    "        on=\"psu_hh_idcode\",\n",
    "        how=\"left\",\n",
    "        suffixes=[None, \"_house\"],\n",
    "    ),\n",
    "    df_edu_prefixed,\n",
    "    on=\"psu_hh_idcode\",\n",
    "    how=\"left\",\n",
    "    suffixes=[None, \"_edu\"],\n",
    ")\n",
    "\n",
    "combined_transformed_train.columns = combined_transformed_train.columns.str.lower()\n",
    "assert combined_transformed_train.shape[0] == pov_train.shape[0]  # same number of rows\n",
    "\n",
    "# save to csv\n",
    "combined_transformed_train.to_csv(\n",
    "    os.path.join(PROCESSED_DIR, \"combined_transformed_train.csv\"), index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1334, 99)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now test data\n",
    "df_house_test[\"psu_hh_idcode\"] = (\n",
    "    df_house_test[\"psu\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_house_test[\"hh\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_house_test[\"idcode\"].astype(str)\n",
    ")\n",
    "df_edu_test[\"psu_hh_idcode\"] = (\n",
    "    df_edu_test[\"psu\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_edu_test[\"hh\"].astype(str)\n",
    "    + \"_\"\n",
    "    + df_edu_test[\"idcode\"].astype(str)\n",
    ")\n",
    "df_house_test_prefixed = df_house_test.drop(\n",
    "    columns=[\"psu\", \"hh\", \"idcode\", \"hhid\"]\n",
    ").add_prefix(\"house_\")\n",
    "df_edu_test_prefixed = df_edu_test.drop(columns=[\"psu\", \"hh\", \"idcode\"]).add_prefix(\n",
    "    \"edu_\"\n",
    ")\n",
    "\n",
    "# remove prefix on the key merge column \"psh_hh_idcode\"\n",
    "df_house_test_prefixed = df_house_test_prefixed.rename(\n",
    "    columns={\"house_psu_hh_idcode\": \"psu_hh_idcode\"}\n",
    ")\n",
    "df_edu_test_prefixed = df_edu_test_prefixed.rename(\n",
    "    columns={\"edu_psu_hh_idcode\": \"psu_hh_idcode\"}\n",
    ")\n",
    "\n",
    "combined_test = pd.merge(\n",
    "    pd.merge(\n",
    "        sample_submission,\n",
    "        df_house_test_prefixed,\n",
    "        on=\"psu_hh_idcode\",\n",
    "        how=\"left\",\n",
    "        suffixes=[None, \"_house\"],\n",
    "    ),\n",
    "    df_edu_test_prefixed,\n",
    "    on=\"psu_hh_idcode\",\n",
    "    how=\"left\",\n",
    "    suffixes=[None, \"_edu\"],\n",
    ")\n",
    "combined_test.columns = combined_test.columns.str.lower()\n",
    "assert combined_test.shape[0] == sample_submission.shape[0]  # same number of rows\n",
    "\n",
    "# save to csv\n",
    "combined_test.to_csv(\n",
    "    os.path.join(PROCESSED_DIR, \"combined_transformed_test.csv\"), index=False\n",
    ")\n",
    "combined_test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sta841kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
