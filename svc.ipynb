{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_q02</th>\n",
       "      <th>house_q03</th>\n",
       "      <th>house_q04</th>\n",
       "      <th>house_q05y</th>\n",
       "      <th>house_q05m</th>\n",
       "      <th>house_q06</th>\n",
       "      <th>house_q07</th>\n",
       "      <th>house_q08</th>\n",
       "      <th>house_q09</th>\n",
       "      <th>house_q11</th>\n",
       "      <th>...</th>\n",
       "      <th>edu_q57</th>\n",
       "      <th>edu_q58</th>\n",
       "      <th>edu_q59</th>\n",
       "      <th>edu_q60</th>\n",
       "      <th>edu_q61</th>\n",
       "      <th>edu_q62</th>\n",
       "      <th>edu_q63</th>\n",
       "      <th>edu_q64</th>\n",
       "      <th>edu_q65</th>\n",
       "      <th>edu_q66</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19680615.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19640910.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19510317.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19460402.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19400407.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5332</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19390126.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5333</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19520312.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5334</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19570125.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5335</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19581225.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19340403.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5337 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      house_q02  house_q03   house_q04  house_q05y  house_q05m  house_q06  \\\n",
       "0           1.0        1.0  19680615.0        44.0         2.0        1.0   \n",
       "1           2.0        2.0  19640910.0        48.0         0.0        1.0   \n",
       "2           1.0        1.0  19510317.0        61.0         5.0        1.0   \n",
       "3           1.0        1.0  19460402.0        66.0         5.0        1.0   \n",
       "4           2.0        1.0  19400407.0        72.0         5.0        4.0   \n",
       "...         ...        ...         ...         ...         ...        ...   \n",
       "5332        2.0        1.0  19390126.0        73.0         7.0        4.0   \n",
       "5333        1.0        1.0  19520312.0        60.0         6.0        1.0   \n",
       "5334        1.0        1.0  19570125.0        55.0         7.0        1.0   \n",
       "5335        1.0        1.0  19581225.0        53.0         8.0        1.0   \n",
       "5336        1.0        1.0  19340403.0        78.0         5.0        1.0   \n",
       "\n",
       "      house_q07  house_q08  house_q09  house_q11  ...  edu_q57  edu_q58  \\\n",
       "0           1.0        2.0        0.0        2.0  ...      NaN      NaN   \n",
       "1           1.0        1.0        0.0        2.0  ...      NaN      NaN   \n",
       "2           1.0        2.0        0.0        2.0  ...      NaN      NaN   \n",
       "3           1.0        2.0        0.0        2.0  ...      NaN      NaN   \n",
       "4           NaN        NaN        0.0        2.0  ...      NaN      NaN   \n",
       "...         ...        ...        ...        ...  ...      ...      ...   \n",
       "5332        NaN        NaN        0.0        2.0  ...      NaN      NaN   \n",
       "5333        1.0        2.0        0.0        2.0  ...      NaN      NaN   \n",
       "5334        1.0        2.0        0.0        2.0  ...      NaN      NaN   \n",
       "5335        1.0        2.0        0.0        1.0  ...      NaN      NaN   \n",
       "5336        1.0        2.0        0.0        2.0  ...      NaN      NaN   \n",
       "\n",
       "      edu_q59  edu_q60  edu_q61  edu_q62  edu_q63  edu_q64  edu_q65  edu_q66  \n",
       "0         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "1         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "2         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "3         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "4         NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...  \n",
       "5332      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "5333      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "5334      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "5335      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "5336      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN  \n",
       "\n",
       "[5337 rows x 87 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna\n",
    "\n",
    "from data import Y_COLUMNS, combined_train, sample_submission\n",
    "\n",
    "\n",
    "SEED = 842\n",
    "DATA_DIR = \"processed\"\n",
    "\n",
    "X, y_binarized = (\n",
    "    combined_train.drop(Y_COLUMNS, axis=1),\n",
    "    combined_train[Y_COLUMNS],\n",
    ")\n",
    "\n",
    "y = np.argmax(y_binarized.values, axis=1)\n",
    "\n",
    "# null_threshold = 0.2\n",
    "# dropped_columns = X.columns[X.isnull().mean() > null_threshold]\n",
    "# X = X.drop(dropped_columns, axis=1)\n",
    "X = X.drop([\"house_q10\"], axis=1)\n",
    "X = X.iloc[:, 1:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 34. Best value: 1.92905:  13%|█▎        | 63/500 [00:08<01:10,  6.16it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 34. Best value: 1.92905:  14%|█▎        | 68/500 [00:08<00:45,  9.48it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 79. Best value: 1.92755:  17%|█▋        | 86/500 [00:10<00:41, 10.02it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 133. Best value: 1.92581:  26%|██▋       | 132/500 [00:17<01:02,  5.93it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 133. Best value: 1.92581:  30%|███       | 152/500 [00:20<00:55,  6.27it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 133. Best value: 1.92581:  31%|███▏      | 157/500 [00:21<00:46,  7.35it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 133. Best value: 1.92581:  33%|███▎      | 164/500 [00:21<00:38,  8.69it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 133. Best value: 1.92581:  35%|███▌      | 176/500 [00:23<00:30, 10.54it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 133. Best value: 1.92581:  58%|█████▊    | 290/500 [00:33<00:21,  9.91it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 321. Best value: 1.92581:  69%|██████▊   | 343/500 [00:38<00:12, 12.41it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 321. Best value: 1.92581:  84%|████████▎ | 418/500 [00:44<00:06, 11.81it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 321. Best value: 1.92581:  85%|████████▌ | 427/500 [00:45<00:07, 10.32it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "Best trial: 321. Best value: 1.92581: 100%|██████████| 500/500 [00:51<00:00,  9.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "MAX_ITER = 20000\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    null_threshold = trial.suggest_float(\"null_threshold\", 0.05, 0.5)\n",
    "    cv = trial.suggest_int(\"cv\", 3, 5)\n",
    "    imputer_strategy = trial.suggest_categorical(\n",
    "        \"imputer_strategy\", [\"mean\", \"median\", \"most_frequent\"]\n",
    "    )\n",
    "    scaler = trial.suggest_categorical(\"scaler\", [\"minmax\", \"standard\"])\n",
    "    C = trial.suggest_float(\"C\", 1e-10, 1e10, log=True)\n",
    "    penalty = trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"])\n",
    "    intercept_scaling = trial.suggest_float(\"intercept_scaling\", 1e-10, 1e10, log=True)\n",
    "\n",
    "    dropped_columns = X.columns[X.isnull().mean() > null_threshold]\n",
    "    X_cleaned = X.drop(dropped_columns, axis=1)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid, y_train_binarized, y_valid_binarized = (\n",
    "        train_test_split(X_cleaned, y, y_binarized, test_size=1 / cv, random_state=SEED)\n",
    "    )\n",
    "    imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_valid_imputed = imputer.transform(X_valid)\n",
    "    if scaler == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train_imputed)\n",
    "    X_valid = scaler.transform(X_valid_imputed)\n",
    "\n",
    "    model = LinearSVC(\n",
    "        C=C,\n",
    "        penalty=penalty,\n",
    "        intercept_scaling=intercept_scaling,\n",
    "        max_iter=MAX_ITER,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    calibration_method = trial.suggest_categorical(\n",
    "        \"calibration_method\", [\"sigmoid\", \"isotonic\"]\n",
    "    )\n",
    "    calibrated_model = CalibratedClassifierCV(\n",
    "        model, cv=\"prefit\", method=calibration_method\n",
    "    )\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "    train_loss = log_loss(\n",
    "        y_train_binarized, calibrated_model.predict_proba(X_train), normalize=False\n",
    "    ) / len(y_train_binarized)\n",
    "\n",
    "    y_pred = calibrated_model.predict_proba(X_valid)\n",
    "    valid_loss = log_loss(y_valid_binarized, y_pred, normalize=False) / len(\n",
    "        y_valid_binarized\n",
    "    )\n",
    "\n",
    "    trial.set_user_attr(\"train_score\", model.score(X_train, y_train))\n",
    "    trial.set_user_attr(\"train_loss\", train_loss)\n",
    "    trial.set_user_attr(\"valid_loss_shift\", valid_loss - train_loss)\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "storage = f\"sqlite:///svm.db\"\n",
    "study_name = \"svm\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\", storage=storage, study_name=study_name, load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=500, n_jobs=-1, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 55. Best value: 1.93227:  10%|▉         | 48/500 [00:47<11:08,  1.48s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  43%|████▎     | 215/500 [02:31<02:03,  2.30it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  45%|████▌     | 227/500 [02:40<03:07,  1.46it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  56%|█████▌    | 281/500 [04:19<17:07,  4.69s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  58%|█████▊    | 288/500 [05:52<24:27,  6.92s/it]  /Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  61%|██████    | 305/500 [06:57<16:55,  5.21s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  62%|██████▏   | 311/500 [07:13<08:05,  2.57s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  66%|██████▌   | 329/500 [07:43<04:38,  1.63s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  68%|██████▊   | 340/500 [07:58<02:52,  1.08s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  70%|██████▉   | 348/500 [08:06<02:36,  1.03s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  70%|███████   | 351/500 [08:08<01:44,  1.43it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  71%|███████   | 353/500 [08:09<01:45,  1.40it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  74%|███████▎  | 368/500 [08:18<01:13,  1.80it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  74%|███████▍  | 372/500 [08:20<01:04,  2.00it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  79%|███████▉  | 394/500 [08:33<01:32,  1.15it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 158. Best value: 1.9321:  81%|████████  | 405/500 [08:39<01:02,  1.51it/s]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 420. Best value: 1.9321: 100%|█████████▉| 498/500 [10:04<00:22, 11.12s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 420. Best value: 1.9321: 100%|█████████▉| 499/500 [11:12<00:27, 27.83s/it]/Users/borisleung/anaconda3/envs/sta841kaggle/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "Best trial: 420. Best value: 1.9321: 100%|██████████| 500/500 [11:51<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "MAX_ITER = int(1e6)\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "    null_threshold = trial.suggest_float(\"null_threshold\", 0.05, 0.5)\n",
    "    cv = trial.suggest_int(\"cv\", 3, 5)\n",
    "    imputer_strategy = trial.suggest_categorical(\n",
    "        \"imputer_strategy\", [\"mean\", \"median\", \"most_frequent\"]\n",
    "    )\n",
    "    scaler = trial.suggest_categorical(\"scaler\", [\"minmax\", \"standard\"])\n",
    "    C = trial.suggest_float(\"C\", 1e-5, 1e5, log=True)\n",
    "    kernel = trial.suggest_categorical(\"kernel\", [\"poly\", \"rbf\", \"sigmoid\"])\n",
    "\n",
    "    dropped_columns = X.columns[X.isnull().mean() > null_threshold]\n",
    "    X_cleaned = X.drop(dropped_columns, axis=1)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid, y_train_binarized, y_valid_binarized = (\n",
    "        train_test_split(X_cleaned, y, y_binarized, test_size=1 / cv, random_state=SEED)\n",
    "    )\n",
    "    imputer = SimpleImputer(strategy=imputer_strategy)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_valid_imputed = imputer.transform(X_valid)\n",
    "    if scaler == \"standard\":\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train_imputed)\n",
    "    X_valid = scaler.transform(X_valid_imputed)\n",
    "\n",
    "    if kernel == \"poly\":\n",
    "        degree = trial.suggest_int(\"degree\", 2, 5)\n",
    "        model = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            degree=degree,\n",
    "            max_iter=MAX_ITER,\n",
    "            random_state=SEED,\n",
    "            probability=True,\n",
    "        )\n",
    "    else:\n",
    "        model = SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            max_iter=MAX_ITER,\n",
    "            random_state=SEED,\n",
    "            probability=True,\n",
    "        )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    train_loss = log_loss(\n",
    "        y_train_binarized, model.predict_proba(X_train), normalize=False\n",
    "    ) / len(y_train_binarized)\n",
    "\n",
    "    y_pred = model.predict_proba(X_valid)\n",
    "    valid_loss = log_loss(y_valid_binarized, y_pred, normalize=False) / len(\n",
    "        y_valid_binarized\n",
    "    )\n",
    "\n",
    "    trial.set_user_attr(\"train_score\", model.score(X_train, y_train))\n",
    "    trial.set_user_attr(\"train_loss\", train_loss)\n",
    "    trial.set_user_attr(\"valid_loss_shift\", valid_loss - train_loss)\n",
    "    return valid_loss\n",
    "\n",
    "\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "storage = f\"sqlite:///svm.db\"\n",
    "study_name = \"kernel-svc\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\", storage=storage, study_name=study_name, load_if_exists=True\n",
    ")\n",
    "study.optimize(objective, n_trials=500, n_jobs=-1, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9115197552925864"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "linear_study = optuna.create_study(\n",
    "    direction=\"minimize\", storage=storage, study_name=\"linear-svc\", load_if_exists=True\n",
    ")\n",
    "linear_best_trial = linear_study.best_trial\n",
    "null_threshold = linear_best_trial.params[\"null_threshold\"]\n",
    "dropped_columns = X.columns[X.isnull().mean() > null_threshold]\n",
    "X_cleaned = X.drop(dropped_columns, axis=1)\n",
    "\n",
    "final_imputer = SimpleImputer(strategy=linear_best_trial.params[\"imputer_strategy\"])\n",
    "X_imputed = final_imputer.fit_transform(X_cleaned)\n",
    "\n",
    "if linear_best_trial.params[\"scaler\"] == \"standard\":\n",
    "    final_scaler = StandardScaler()\n",
    "elif linear_best_trial.params[\"scaler\"] == \"minmax\":\n",
    "    final_scaler = MinMaxScaler()\n",
    "X_scaled = final_scaler.fit_transform(X_imputed)\n",
    "\n",
    "C = linear_best_trial.params[\"C\"]\n",
    "penalty = linear_best_trial.params[\"penalty\"]\n",
    "intercept_scaling = linear_best_trial.params[\"intercept_scaling\"]\n",
    "final_model = LinearSVC(\n",
    "    C=C,\n",
    "    penalty=penalty,\n",
    "    intercept_scaling=intercept_scaling,\n",
    "    max_iter=MAX_ITER * 5,\n",
    "    random_state=SEED,\n",
    ")\n",
    "final_model.fit(X_scaled, y)\n",
    "calibration_method = linear_best_trial.params[\"calibration_method\"]\n",
    "final_calibrated_model = CalibratedClassifierCV(\n",
    "    final_model, cv=\"prefit\", method=calibration_method\n",
    ")\n",
    "final_calibrated_model.fit(X_scaled, y)\n",
    "\n",
    "final_y_train_pred = final_calibrated_model.predict_proba(X_scaled)\n",
    "\n",
    "log_loss(y_binarized, final_y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as linear-svc-1.csv\n"
     ]
    }
   ],
   "source": [
    "from data import generate_submission, combined_test\n",
    "\n",
    "X_submissions = combined_test.drop(Y_COLUMNS, axis=1)\n",
    "X_submissions = X_submissions.drop(dropped_columns, axis=1)\n",
    "X_submissions = X_submissions.drop([\"house_q10\"], axis=1)\n",
    "X_submissions = X_submissions.iloc[:, 1:]\n",
    "X_submissions_imputed = final_imputer.transform(X_submissions)\n",
    "X_submissions_scaled = final_scaler.transform(X_submissions_imputed)\n",
    "final_y_pred = final_calibrated_model.predict_proba(X_submissions_scaled)\n",
    "\n",
    "generate_submission(final_y_pred, \"linear-svc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9124056593435594"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_study = optuna.create_study(\n",
    "    direction=\"minimize\", storage=storage, study_name=\"kernel-svc\", load_if_exists=True\n",
    ")\n",
    "kernel_best_trial = kernel_study.best_trial\n",
    "null_threshold = kernel_best_trial.params[\"null_threshold\"]\n",
    "dropped_columns = X.columns[X.isnull().mean() > null_threshold]\n",
    "X_cleaned = X.drop(dropped_columns, axis=1)\n",
    "\n",
    "final_imputer = SimpleImputer(strategy=kernel_best_trial.params[\"imputer_strategy\"])\n",
    "X_imputed = final_imputer.fit_transform(X_cleaned)\n",
    "\n",
    "if kernel_best_trial.params[\"scaler\"] == \"standard\":\n",
    "    final_scaler = StandardScaler()\n",
    "elif kernel_best_trial.params[\"scaler\"] == \"minmax\":\n",
    "    final_scaler = MinMaxScaler()\n",
    "X_scaled = final_scaler.fit_transform(X_imputed)\n",
    "\n",
    "kernel = kernel_best_trial.params[\"kernel\"]\n",
    "C = kernel_best_trial.params[\"C\"]\n",
    "if kernel == \"poly\":\n",
    "    degree = kernel_best_trial.params[\"degree\"]\n",
    "    final_model = SVC(\n",
    "        C=C,\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        max_iter=MAX_ITER * 5,\n",
    "        random_state=SEED,\n",
    "        probability=True,\n",
    "    )\n",
    "else:\n",
    "    final_model = SVC(\n",
    "        C=C, kernel=kernel, max_iter=MAX_ITER * 5, random_state=SEED, probability=True\n",
    "    )\n",
    "final_model.fit(X_scaled, y)\n",
    "\n",
    "final_y_train_pred = final_model.predict_proba(X_scaled)\n",
    "\n",
    "log_loss(y_binarized, final_y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as kernel-svc-1.csv\n"
     ]
    }
   ],
   "source": [
    "from data import generate_submission, combined_test\n",
    "\n",
    "X_submissions = combined_test.drop(Y_COLUMNS, axis=1)\n",
    "X_submissions = X_submissions.drop(dropped_columns, axis=1)\n",
    "X_submissions = X_submissions.drop([\"house_q10\"], axis=1)\n",
    "X_submissions = X_submissions.iloc[:, 1:]\n",
    "X_submissions_imputed = final_imputer.transform(X_submissions)\n",
    "X_submissions_scaled = final_scaler.transform(X_submissions_imputed)\n",
    "final_y_pred = final_model.predict_proba(X_submissions_scaled)\n",
    "\n",
    "generate_submission(final_y_pred, \"kernel-svc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sta841kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
